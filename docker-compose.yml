version: '3.8'

services:
  nginx:
    image: nginx:alpine
    depends_on:
      - frontend
      - backend
    ports:
      - "${HOST_PORT:-8080}:80"
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
    networks:
      - optormc_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O- http://localhost >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 5

  frontend:
    build:
      context: ./frontend
      target: deps
    command: ["npm", "run", "dev"]
    depends_on:
      - backend
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - ./shared-outputs:/app/shared-outputs
    networks:
      - optormc_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "node -e \"fetch('http://localhost:3000').then(r=>process.exit(r.ok?0:1)).catch(()=>process.exit(1))\" "]
      interval: 10s
      timeout: 3s
      retries: 10

  backend:
    build: ./backend
    depends_on:
      - ollama
    volumes:
      - ./shared-outputs:/app/shared-outputs
    networks:
      - optormc_net
    healthcheck:
      test: ["CMD-SHELL", "node -e \"fetch('http://localhost:5000/health').then(r=>process.exit(r.ok?0:1)).catch(()=>process.exit(1))\" "]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama/models
    networks:
      - optormc_net

volumes:
  ollama-models:

networks:
  optormc_net:
    driver: bridge
